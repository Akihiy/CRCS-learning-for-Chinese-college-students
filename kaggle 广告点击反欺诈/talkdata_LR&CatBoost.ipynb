{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './input/'\n",
    "\n",
    "train_columns = ['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed']\n",
    "test_columns  = ['ip', 'app', 'device', 'os', 'channel', 'click_time', 'click_id']\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32'\n",
    "        }\n",
    "\n",
    "# 97903891 = 184903891 - 87000000\n",
    "train = pd.read_csv(path+'train.csv', usecols=train_columns, dtype=dtypes, skiprows=range(1, 97903891), nrows=87000000, parse_dates=['click_time'])\n",
    "# train = pd.read_csv(path+'train.csv', usecols=train_columns, dtype=dtypes, parse_dates=['click_time'])\n",
    "test = pd.read_csv(path+'test.csv', usecols=test_columns, dtype=dtypes, parse_dates=['click_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集label\n",
    "y_train = train['is_attributed'].values\n",
    "\n",
    "sub = test[['click_id']]\n",
    "del test['click_id']\n",
    "\n",
    "# 训练集与测试集合并\n",
    "data = pd.concat([train, test], axis=0)\n",
    "del train, test\n",
    "gc.collect()\n",
    "\n",
    "# 时间处理\n",
    "data['day'] = data['click_time'].dt.day.astype('uint8')\n",
    "data['hour'] = data['click_time'].dt.hour.astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目标编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cols in tqdm([['ip'], ['app'], ['ip','app'], ['ip','hour'], ['ip','os','device'], ['ip','app','os','device'], ['app','os','channel']]):\n",
    "#     name = '_'.join(cols)\n",
    "#     res = pd.DataFrame()\n",
    "#     temp = data[cols + ['day', 'is_attributed']]\n",
    "#     for period in [7,8,9,10]:\n",
    "#         mean_ = temp[temp['day']<period].groupby(cols)['is_attributed'].mean().reset_index(name=name + '_mean_is_attributed')\n",
    "#         mean_['day'] = period\n",
    "#         res = res.append(mean_, ignore_index=True)\n",
    "    \n",
    "#     data = pd.merge(data, res, how='left', on=['day']+cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保留7 8 9 10号数据\n",
    "data = data[data['day']>=7]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:48<00:00, 13.99s/it]\n",
      "100%|██████████| 4/4 [03:51<00:00, 60.41s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count\n",
    "for cols in tqdm([['ip'],['ip','os','device'],['ip','day','hour']]):\n",
    "    name = '_'.join(cols)\n",
    "    data[name+'_cnts'] = data.groupby(cols)['click_time'].transform('count')\n",
    "    data[name+'_cnts'] = data[name+'_cnts'].astype('uint16')\n",
    "\n",
    "# nunique\n",
    "for f1 in ['ip']:\n",
    "    for f2 in tqdm(['app','device','os','channel']):\n",
    "        data[f1+'_'+f2+'_nuni'] = data.groupby([f1])[f2].transform('nunique')\n",
    "        data[f1+'_'+f2+'_nuni'] = data[f1+'_'+f2+'_nuni'].astype('uint16') \n",
    "            \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 时间差特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [22:39<00:00, 652.64s/it]\n"
     ]
    }
   ],
   "source": [
    "for cols in tqdm([['ip','os','device','app'],['ip','os','device','app','day']]):\n",
    "    for i in range(1,6):\n",
    "        \n",
    "        data['ct'] = (data['click_time'].astype(np.int64)//10**9).astype(np.int32)\n",
    "        \n",
    "        name = '{}_next_{}_click'.format('_'.join(cols), str(i))\n",
    "        data[name] = (data.groupby(cols).ct.shift(-i)-data.ct).astype(np.float32)\n",
    "        data[name] = data[name].fillna(data[name].mean())\n",
    "        data[name] = data[name].astype('uint16')\n",
    "        \n",
    "        name = '{}_lag_{}_click'.format('_'.join(cols), str(i))\n",
    "        data[name] = (data.groupby(cols).ct.shift(i)-data.ct).astype(np.float32)\n",
    "        data[name] = data[name].fillna(data[name].mean())\n",
    "        data[name] = data[name].astype('uint16')\n",
    "        \n",
    "        data.drop(['ct'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ['ip', 'os', 'device', 'app']\n",
    "data['click_user_lab'] = 0\n",
    "pos = data.duplicated(subset=subset, keep=False)\n",
    "data.loc[pos, 'click_user_lab'] = 1\n",
    "pos = (~data.duplicated(subset=subset, keep='first')) & data.duplicated(subset=subset, keep=False)\n",
    "data.loc[pos, 'click_user_lab'] = 2\n",
    "pos = (~data.duplicated(subset=subset, keep='last')) & data.duplicated(subset=subset, keep=False)\n",
    "data.loc[pos, 'click_user_lab'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 排序特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [05:57<00:00, 174.67s/it]\n"
     ]
    }
   ],
   "source": [
    "for cols in tqdm([['ip','os','device','app'],['ip','os','device','app','day']]):\n",
    "    name = '{}_click_asc_rank'.format('_'.join(cols)) \n",
    "    data[name] = data.groupby(cols)['click_time'].rank(ascending=True)\n",
    "    \n",
    "    name = '{}_click_dec_rank'.format('_'.join(cols)) \n",
    "    data[name] = data.groupby(cols)['click_time'].rank(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集/验证集/测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['ip','app','os','channel','device','day','hour']\n",
    "features = [f for f in data.columns if f not in ['click_time','is_attributed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 9584.52 Mb (28.0% reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = reduce_mem_usage(data)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 负采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_neg = data[(data['is_attributed'] == 0)&(data['day'] < 9)]\n",
    "# df_rest = data[(data['is_attributed'] == 1)|(data['day'] >= 9)]\n",
    "# del data\n",
    "# gc.collect()\n",
    "\n",
    "# df_train_neg = df_train_neg.sample(n=1000000)\n",
    "# data = pd.concat([df_train_neg,df_rest]).sample(frac=1)\n",
    "# del df_train_neg\n",
    "# del df_rest\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_x = data[:82000000][features]\n",
    "val_x = data[82000000:87000000][features]\n",
    "trn_y = y_train[:82000000]\n",
    "val_y = y_train[82000000:87000000]\n",
    "\n",
    "# test_x = data[87000000:][features]\n",
    "\n",
    "# trn_x = data[data['day']<9][features]\n",
    "# trn_y = data[data['day']<9]['is_attributed']\n",
    "\n",
    "# val_x = data[data['day']==9][features]\n",
    "# val_y = data[data['day']==9]['is_attributed']\n",
    "\n",
    "# test_x = data[data['day']>9][features]\n",
    "\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype uint8, uint16, uint32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype uint8, uint16, uint32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype uint8, uint16, uint32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype uint8, uint16, uint32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(pd.concat([trn_x, val_x, test_x]))\n",
    "trn_x[:] = scaler.transform(trn_x)\n",
    "val_x[:] = scaler.transform(val_x)\n",
    "test_x[:] = scaler.transform(test_x)\n",
    "\n",
    "trn_x = trn_x.fillna(0)\n",
    "val_x = val_x.fillna(0)\n",
    "test_x = test_x.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(C=5, solver='sag')\n",
    "model.fit(trn_x, trn_y)\n",
    "val_preds = model.predict_proba(val_x)[:,1]\n",
    "preds = model.predict_proba(test_x)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8884591003977454"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(val_y, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['is_attributed'] = None\n",
    "sub['is_attributed'] = preds\n",
    "sub.to_csv('lr_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:55:01] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "[0]\ttrain-auc:0.93852\tvalid-auc:0.943594\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 20 rounds.\n",
      "[10]\ttrain-auc:0.972529\tvalid-auc:0.973617\n",
      "[20]\ttrain-auc:0.980228\tvalid-auc:0.980547\n",
      "[30]\ttrain-auc:0.9836\tvalid-auc:0.984491\n",
      "[40]\ttrain-auc:0.985808\tvalid-auc:0.986155\n",
      "[50]\ttrain-auc:0.986874\tvalid-auc:0.986675\n",
      "[60]\ttrain-auc:0.987723\tvalid-auc:0.987025\n",
      "[70]\ttrain-auc:0.988345\tvalid-auc:0.987108\n",
      "[80]\ttrain-auc:0.988892\tvalid-auc:0.987193\n",
      "[90]\ttrain-auc:0.989311\tvalid-auc:0.987247\n",
      "[100]\ttrain-auc:0.989615\tvalid-auc:0.987265\n",
      "[110]\ttrain-auc:0.99008\tvalid-auc:0.98721\n",
      "Stopping. Best iteration:\n",
      "[97]\ttrain-auc:0.989531\tvalid-auc:0.987325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'eta': 0.2,\n",
    "          'max_leaves': 2**9-1,  \n",
    "          'max_depth': 9, \n",
    "          'subsample': 0.7, \n",
    "          'colsample_bytree': 0.9, \n",
    "          'objective': 'binary:logistic', \n",
    "          'scale_pos_weight':9,\n",
    "          'eval_metric': 'auc', \n",
    "          'n_jobs':24,\n",
    "          'random_state': 2020,\n",
    "          'silent': True}\n",
    "          \n",
    "dtrain = xgb.DMatrix(trn_x, trn_y)\n",
    "dvalid = xgb.DMatrix(val_x, val_y)\n",
    "gc.collect()\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "model = xgb.train(params, dtrain, 200, watchlist, early_stopping_rounds = 20, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(test_x)\n",
    "sub['is_attributed'] = None\n",
    "sub['is_attributed'] = model.predict(dtest, ntree_limit=model.best_ntree_limit)\n",
    "sub.to_csv('talkingdata_xgboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.9425938\tbest: 0.9425938 (0)\ttotal: 1m 3s\tremaining: 14d 16h 41m 38s\n",
      "10:\ttest: 0.9533948\tbest: 0.9533948 (10)\ttotal: 10m 47s\tremaining: 13d 14h 38m 9s\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate': 0.1,\n",
    "          'depth': 8,\n",
    "          'l2_leaf_reg': 10,\n",
    "          'bootstrap_type': 'Bernoulli',\n",
    "          'od_type': 'Iter',\n",
    "          'od_wait': 50,\n",
    "          'random_seed': 11,\n",
    "          'allow_writing_files': False}\n",
    "          \n",
    "model = CatBoostClassifier(iterations=20000, eval_metric='AUC', **params)\n",
    "model.fit(trn_x, trn_y,\n",
    "          eval_set=(val_x, val_y),\n",
    "          cat_features=categorical_features, \n",
    "          use_best_model=True, \n",
    "          early_stopping_rounds=50,\n",
    "          verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['is_attributed'] = None\n",
    "sub['is_attributed'] = model.predict_proba(test_x)[:,1]\n",
    "sub.to_csv('talkingdata_catboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (PySpark)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
